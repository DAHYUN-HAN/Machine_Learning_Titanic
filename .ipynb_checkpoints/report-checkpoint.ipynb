{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggle 사용을 위한 준비단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colab에서 g란 이름으로 구글드라이브의 root를 MOUNT\n",
    "from google.colab import drive\n",
    "drive.mount('/content/g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp \"/content/g/My Drive/kaggle/kaggle.json\" ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### titanic 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "titanic 데이터는 **891행**으로 이루어져 있는 **train 데이터**와 **418행**으로 이루어져 있는 **test 데이터**를 가지고 있다.  \n",
    "  \n",
    "**<center>데이터 구성</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|변수|설명|비고|데이터유형|구분|\n",
    "|------|---|---|---|---|\n",
    "|PassengerId|승객번호||int|\n",
    "|Survived|생존여부|0 = No, 1 = Yes|int|범주형|\n",
    "|Pclass|객실등급|1 = 1등급, 2 = 2등급, 3 = 3등급|int|범주형|\n",
    "|Name|승객이름||object||\n",
    "|Sex|성별|male, female|object|범주형|\n",
    "|Age|나이||float||\n",
    "|SibSp|함께 탑승한 형제와 배우자의 수|형제수 + 배우자수|int||\n",
    "|Parch|함께 탑승한 부모와 아이의 수|부모수 + 자녀수|int||\n",
    "|Ticket|티겟 번호||object||\n",
    "|Fare|탑승 요금||float||\n",
    "|Cabin|객실 번호|공백도 많고 정확한 기준을 알 수 없다|object||\n",
    "|Embarked|탑승 항구|C=Cherbourg, Q=Queenstown, S=Southampton|object|범주형|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "**필요 없는 열 삭제**  \n",
    "생존여부를 판단하는데에 있어 필요하지 않다고 생각하는 열을 삭제하기로 하였다.  \n",
    "  \n",
    "PassengerId = 인덱스처럼 1부터 순차적으로 증가하는 값을 가지고 있어 생존여부에 관여하지 않는다.  \n",
    "Name = 탑승자의 이름은 생존여부와 관련이 없다.  \n",
    "Ticket = 탑승자의 티켓 번호는 생존여부와 관련이 없다.\n",
    "Cabin = 객실 번호는 공백이 많기 때문에 대체하기 어려워 삭제를 진행하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['PassengerId']\n",
    "del df_train['Name']\n",
    "del df_train['Ticket']\n",
    "del df_train['Cabin']\n",
    "del df_test['PassengerId']\n",
    "del df_test['Name']\n",
    "del df_test['Ticket']\n",
    "del df_test['Cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Embarked').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embarked 열에서 최다 빈도는 S 이므로 결측치를 일괄적으로 S로 채우기로 하였고,  \n",
    "Age 열은 나이의 평균값으로 결측치를 채우기로 하였다.  \n",
    "train 데이터 Age 평균 : 29.699117647058763  \n",
    "test 데이터 Age 평균 : 30.272590361445815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Embarked']=df_train['Embarked'].fillna('S')\n",
    "df_train['Age']=df_train['Age'].fillna(df_train['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Fare']=df_test['Fare'].fillna(df_test['Fare'].mean())\n",
    "df_test['Age']=df_test['Age'].fillna(df_test['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 열 처리\n",
    "int 및 object 타입으로 되어 있던 범주형 열인 Sex, Pclass, Embarked 열을 category 타입으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sex']=df_train['Sex'].astype('category')\n",
    "df_train['Pclass']=df_train['Pclass'].astype('category')\n",
    "df_train['Embarked']=df_train['Embarked'].astype('category')\n",
    "df_train = pd.get_dummies(df_train)\n",
    "\n",
    "df_test['Sex']=df_test['Sex'].astype('category')\n",
    "df_test['Pclass']=df_test['Pclass'].astype('category')\n",
    "df_test['Embarked']=df_test['Embarked'].astype('category')\n",
    "df_test = pd.get_dummies(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_train의 라벨은 Survived로 0번 열에 해당."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df_train.iloc[:,1:]\n",
    "y_data = df_train.iloc[:,0]\n",
    "\n",
    "x_data = x_data.values\n",
    "y_data = y_data.values\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_data = df_test.iloc[:,1:]\n",
    "\n",
    "x2_data = x2_data.values\n",
    "print(x2_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier\n",
    "n_estimators=100, criterion=\"gini\", max_depth=None, min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=\"auto\",\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None,\n",
    "                 bootstrap=True,\n",
    "                 oob_score=False,\n",
    "                 n_jobs=None,\n",
    "                 random_state=None,\n",
    "                 verbose=0,\n",
    "                 warm_start=False,\n",
    "                 class_weight=None,\n",
    "                 ccp_alpha=0.0,\n",
    "                 max_samples=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators\t- 결정트리의 갯수를 지정\n",
    "- Default = 10\n",
    "- 무작정 트리 갯수를 늘리면 성능 좋아지는 것 대비 시간이 걸릴 수 있음  \n",
    "\n",
    "min_samples_split\t- 노드를 분할하기 위한 최소한의 샘플 데이터수\n",
    "→ 과적합을 제어하는데 사용\n",
    "- Default = 2 → 작게 설정할 수록 분할 노드가 많아져 과적합 가능성 증가  \n",
    "\n",
    "min_samples_leaf\t- 리프노드가 되기 위해 필요한 최소한의 샘플 데이터수\n",
    "- min_samples_split과 함께 과적합 제어 용도\n",
    "- 불균형 데이터의 경우 특정 클래스의 데이터가 극도로 작을 수 있으므로 작게 설정 필요  \n",
    "\n",
    "max_features\t- 최적의 분할을 위해 고려할 최대 feature 개수\n",
    "- Default = 'auto' (결정트리에서는 default가 none이었음)\n",
    "- int형으로 지정 →피처 갯수 / float형으로 지정 →비중\n",
    "- sqrt 또는 auto : 전체 피처 중 √(피처개수) 만큼 선정\n",
    "- log : 전체 피처 중 log2(전체 피처 개수) 만큼 선정  \n",
    "\n",
    "max_depth\t- 트리의 최대 깊이\n",
    "- default = None\n",
    "→ 완벽하게 클래스 값이 결정될 때 까지 분할\n",
    "또는 데이터 개수가 min_samples_split보다 작아질 때까지 분할\n",
    "- 깊이가 깊어지면 과적합될 수 있으므로 적절히 제어 필요  \n",
    "\n",
    "max_leaf_nodes\t리프노드의 최대 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "  {'n_estimators' : [10, 100], 'max_depth' : [6, 8, 10, 12], 'min_samples_leaf' : [8, 12, 18], 'min_samples_split' : [8, 16, 20]}\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, max_depth = 8, min_samples_leaf = 8, min_samples_split = 20)\n",
    "forest.fit(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = forest.predict(x2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kaggle 제출용 csv 파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame({\"PassengerId\":df_test[\"PassengerId\"], \"Survived\":y_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
